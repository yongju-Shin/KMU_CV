{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zHsC1dqT7C_6"
      },
      "outputs": [],
      "source": [
        "''' CNN MNIST digits classification\n",
        "\n",
        "3-layer CNN for MNIST digits classification \n",
        "First 2 layers - Conv2D-ReLU-MaxPool\n",
        "3rd layer - Conv2D-ReLU-Dropout\n",
        "4th layer - Dense(10)\n",
        "Output Activation - softmax\n",
        "Optimizer - Adam\n",
        "\n",
        "https://github.com/PacktPublishing/Advanced-Deep-Learning-with-Keras\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mnist dataset 로딩\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU5EdRA276ZI",
        "outputId": "f6497235-48c5-4cf5-e7e8-ac7f52b2f482"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 개수 계산\n",
        "num_labels = len(np.unique(y_train))"
      ],
      "metadata": {
        "id": "FHR3tlVQ78cQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot vector로 변환\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "BlkYbZV1795C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 이미지 차원\n",
        "image_size = x_train.shape[1]"
      ],
      "metadata": {
        "id": "GvSxwGsG8GE8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 크기 조정, 정규화\n",
        "x_train = np.reshape(x_train,[-1, image_size, image_size, 1])\n",
        "x_test = np.reshape(x_test,[-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "metadata": {
        "id": "N56IIqEB9oVS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 신경망 하이퍼파라미터\n",
        "# 이미지는 그대로 (정사각형 회식) 처리됨\n",
        "input_shape = (image_size, image_size, 1)\n",
        "batch_size = 128\n",
        "kernel_size = 3\n",
        "pool_size = 2\n",
        "filters = 64\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "Ok_p6snh8IKQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델: CNN-ReLU-MaxPooling 순서로 쌓기\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(MaxPooling2D(pool_size))\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size))\n",
        "model.add(Conv2D(filters=filters,\n",
        "                 kernel_size=kernel_size,\n",
        "                 activation='relu'))\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "QwP8dB658Km4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# regularizer: dropout\n",
        "model.add(Dropout(dropout))"
      ],
      "metadata": {
        "id": "ijTMrdlN-Otq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 출력: 10차원 one-hot vector\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "plot_model(model, to_file='cnn-mnist.png', show_shapes=True)"
      ],
      "metadata": {
        "id": "xH_fmcTU-aq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot vector의 손실함수\n",
        "# 최적화: adam optimizer\n",
        "# 분류 평가 지표: accuracy\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "t3SEclKS8QJA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "-B8UrPuD8XdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 테이터셋으로 일반화 검증\n",
        "loss, acc = model.evaluate(x_test,\n",
        "                        y_test,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=0)\n",
        "print(\"\\nTest accuracy: %.1f%%\" % (100.0 * acc))"
      ],
      "metadata": {
        "id": "1YN2OwbE8ZU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}